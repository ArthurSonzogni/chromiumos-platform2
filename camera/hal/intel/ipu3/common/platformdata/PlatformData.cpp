/*
 * Copyright (C) 2013-2019 Intel Corporation
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#define LOG_TAG "PlatformData"

#include "LogHelper.h"
#include "PlatformData.h"
#include "CameraProfiles.h"
#include "CameraMetadataHelper.h"
#include "cros-camera/v4l2_device.h"
#include "UtilityMacros.h"

#include <linux/media.h>   // media controller
#include <linux/kdev_t.h>  // MAJOR(), MINOR()
#include <sstream>
#include <sys/ioctl.h>
#include <fstream>
#include <fcntl.h>

// TODO this should come from the crl header file
// crl is a common code module in sensor driver, which contains
// basic functions for driver control
#define CRL_CID_SENSOR_MODE 0x00982954

#include "MediaController.h"
#include "MediaEntity.h"

namespace cros {
namespace intel {
using std::string;

bool PlatformData::mInitialized = false;

CameraProfiles* PlatformData::mInstance = nullptr;
CameraHWInfo* PlatformData::mCameraHWInfo = nullptr;
Intel3AClient* PlatformData::mIntel3AClient = nullptr;

/**
 * index to this array is the camera id
 */
CpfStore* PlatformData::sKnownCPFConfigurations[MAX_CPF_CACHED];

GcssKeyMap* PlatformData::mGcssKeyMap = nullptr;

/**
 * Sensor drivers have been registered to media controller
 * or to the main device (old style driver)
 * The actual main device or media controller is detected at runtime
 * (see CameraDetect)
 * These are the default values in case is not detected correctly
 */

static const char *DEFAULT_MAIN_DEVICE = "/dev/video0";

/**
 * The /var/cache/camera directory hosts the device property file required to
 * fill in the tuning cache files generated by the camera HAL at runtime
 */
static const char *CAMERA_CACHE_DIR = "/var/cache/camera/";

/**
 * Property file defines product name and manufactory info
 * Used for EXIF header of JPEG
 * Format: key=value in each line
 */
static const char *CAMERA_PROPERTY_FILE = "camera.prop";

GcssKeyMap::GcssKeyMap()
{
#define GCSS_KEY(key, str) std::make_pair(#str, GCSS_KEY_##key),
#define GCSS_KEY_SECTION_START(key, str, val) GCSS_KEY(key, str)
    mMap = {
        #include "gcss_keys.h"
    };
#undef GCSS_KEY
#undef GCSS_KEY_SECTION_START
}

GcssKeyMap::~GcssKeyMap()
{
}

void GcssKeyMap::gcssKeyMapInsert(std::map<std::string, ia_uid> &customMap)
{
    mMap.insert(customMap.begin(), customMap.end());
}

int GcssKeyMap::gcssKeyMapSize()
{
    return mMap.size();
}

const char* GcssKeyMap::key2str(const ia_uid key)
{
    if (mMap.empty())
         return nullptr;
    std::map<std::string, ia_uid>::const_iterator it = mMap.begin();
    for (;it != mMap.end(); ++it)
        if (it->second == key)
            return it->first.c_str();
    return mMap.begin()->first.c_str();
}
ia_uid GcssKeyMap::str2key(const std::string &key_str)
{
    auto f = mMap.find(key_str);
    if (f != mMap.end())
        return f->second;
    return GCSS_KEY_NA;
}


/**
 * This method is only called once when the HAL library is loaded
 *
 * At this time we can load the XML config (camera3_prfiles.xml)and find the
 * CPF files for all the sensors. Once we load the CPF file
 * we fill the parts of the static metadata that is stored in the CMC
 *
 * Please note that the CpfStore objects are created once but not released
 * This is because this array is only freed if the process is destroyed.
 */
void PlatformData::init()
{
    LOG1("@%s", __FUNCTION__);

    CLEAR(sKnownCPFConfigurations);

    if (mGcssKeyMap) {
        delete mGcssKeyMap;
        mGcssKeyMap = nullptr;
    }
    mGcssKeyMap = new GcssKeyMap;

    if (mCameraHWInfo) {
        delete mCameraHWInfo;
        mCameraHWInfo = nullptr;
    }
    mCameraHWInfo = new CameraHWInfo();

    if (mInstance) {
        delete mInstance;
        mInstance = nullptr;
    }
    mInstance = new CameraProfiles(mCameraHWInfo);

    int ret = mInstance->init();
    if (ret != OK) {
        LOGE("Failed to initialize Camera profiles");
        deinit();
        return;
    }

    int numberOfCameras = PlatformData::numberOfCameras();
    if (numberOfCameras == 0 || numberOfCameras > MAX_CPF_CACHED) {
        LOGE("Camera HAL Basic Platform initialization failed !!number of camera: %d", numberOfCameras);
        deinit();
        return;
    }

    mIntel3AClient = new Intel3AClient;
    if (mIntel3AClient->isInitialized() == false) {
        LOGE("@%s, mIntel3AClient->isInitialized() returns false", __FUNCTION__);
        deinit();
        return;
    }

    /**
     * This number currently comes from the number if sections in the XML
     * in the future this is not reliable if we want to have multiple cameras
     * supported in the same XML.
     * TODO: add a common field in the XML that lists the camera's OR
     * query from driver at runtime
     */
    CpfStore *cpf;
    for (int i = 0; i < numberOfCameras; i++) {
        const CameraCapInfo *cci = PlatformData::getCameraCapInfo(i);
        if (cci == nullptr)
            continue;
        if (cci->sensorType() != SENSOR_TYPE_RAW)
            continue;

        int xmlIndex = PlatformData::getXmlCameraId(i);
        if (xmlIndex < 0) {
            LOGE("@%s, Invalid xml camera index.", __func__);
            deinit();
            return VOID_VALUE;
        }

        // Cpf is using id from XML because aiqb files are named using that id.
        cpf = new CpfStore(xmlIndex, mCameraHWInfo);
        /*
         * As we should not change static metadata on fly, one assumption
         * is that tuning team must make sure that the CMCs keep the same
         * between CPFs of the same sensor.
         * So here fillStaticMetadataFromCMC() is called just once for
         * filling the static metadata. So Please note that only for item 0,
         * AiqConf::mMetadata is initialized.
         */
        for (auto &aiqConfig : cpf->mAiqConfig)
            aiqConfig.second->initCMC();

        auto it = cpf->mAiqConfig.begin();
        if (it != cpf->mAiqConfig.end())
            it->second->fillStaticMetadataFromCMC(mInstance->mStaticMeta[i]);

        sKnownCPFConfigurations[i] = cpf;

        initAiqdInfo(i);
    }

    mInitialized = true;
    LOGD("Camera HAL static init - Done!");
}

/**
 * This method is only called once when the HAL library is unloaded
 */
void PlatformData::deinit() {
    LOG1("@%s", __FUNCTION__);

    if (mCameraHWInfo) {
        saveAiqdDataToFile();
        for (int i = 0; i < numberOfCameras(); i++) {
            mCameraHWInfo->mAiqdDataInfo[i].mData.reset();

            delete sKnownCPFConfigurations[i];
            sKnownCPFConfigurations[i] = nullptr;
        }
        delete mCameraHWInfo;
        mCameraHWInfo = nullptr;
    }

    if (mGcssKeyMap) {
        delete mGcssKeyMap;
        mGcssKeyMap = nullptr;
    }

    if (mInstance) {
        delete mInstance;
        mInstance = nullptr;
    }

    if (mIntel3AClient) {
        delete mIntel3AClient;
        mIntel3AClient = nullptr;
    }

    mInitialized = false;
}

/**
 * static acces method to implement the singleton
 * mInstance should have been instantiated when the library loaded.
 * Having nullptr is a serious error
 */
CameraProfiles *PlatformData::getInstance(void)
{
    if (mInstance == nullptr) {
        LOGE("@%s Failed to create CameraProfiles instance", __FUNCTION__);
        return nullptr;
    }
    return mInstance;
}

GcssKeyMap* PlatformData::getGcssKeyMap()
{
    return mGcssKeyMap;
}

int PlatformData::numberOfCameras(void)
{
    CameraProfiles * i = getInstance();

    if (!i)
        return 0;

    int num = (int)i->mStaticMeta.size();
    return (num <= MAX_CAMERAS) ? num : MAX_CAMERAS;
}

int PlatformData::getXmlCameraId(int cameraId)
{
    CameraProfiles * i = getInstance();

    if (!i)
        return -1;

    return (int)i->getXmlCameraId(cameraId);
}

void PlatformData::getCameraInfo(int cameraId, struct camera_info * info)
{
    info->facing = facing(cameraId);
    info->orientation = orientation(cameraId);
    info->device_version = getCameraDeviceAPIVersion();
    info->static_camera_characteristics = getStaticMetadata(cameraId);
    info->resource_cost = 0;
    info->conflicting_devices = nullptr;
    info->conflicting_devices_length = 0;
}

bool PlatformData::isCpfModeAvailable(int cameraId, string mode)
{
    auto it = sKnownCPFConfigurations[cameraId]->mAiqConfig.find(mode);
    return it != sKnownCPFConfigurations[cameraId]->mAiqConfig.end();
}

const AiqConf* PlatformData::getAiqConfiguration(int cameraId, string mode)
{
    auto it = sKnownCPFConfigurations[cameraId]->mAiqConfig.find(mode);
    if (it == sKnownCPFConfigurations[cameraId]->mAiqConfig.end()) {
       LOGE("mode %s does not map to any AiqConfig!- using default one", mode.c_str());
       return sKnownCPFConfigurations[cameraId]->mAiqConfig.begin()->second;
    }
    LOG1("%s: mode %s, Get AIQ configure", __FUNCTION__, mode.c_str());
    return it->second;
}

/**
 * Function converts the "lens.facing" android static meta data value to
 * value needed by camera service
 * Camera service uses different values from the android metadata
 * Refer system/core/include/system/camera.h
 */

int PlatformData::facing(int cameraId)
{
    uint8_t facing;
    android::CameraMetadata staticMeta;
    staticMeta = getStaticMetadata(cameraId);
    MetadataHelper::getMetadataValue(staticMeta, ANDROID_LENS_FACING, facing);
    facing = (facing == FRONT_CAMERA_ID) ? CAMERA_FACING_BACK : CAMERA_FACING_FRONT;

    return facing;
}

int PlatformData::orientation(int cameraId)
{
    int orientation;
    android::CameraMetadata staticMeta;
    staticMeta = getStaticMetadata(cameraId);
    MetadataHelper::getMetadataValue(staticMeta, ANDROID_SENSOR_ORIENTATION, orientation);

    return orientation;
}

/**
 * Retrieves the partial result count from the static metadata
 * This number is the pieces that we return the the result for a single
 * capture request. This number is specific to PSL implementations
 * It has to be at least 1.
 * \param cameraId[IN]: Camera Id  that we are querying the value for
 * \return value
 */
int PlatformData::getPartialMetadataCount(int cameraId)
{
    int partialMetadataCount = 0;
    android::CameraMetadata staticMeta;
    staticMeta = getStaticMetadata(cameraId);
    MetadataHelper::getMetadataValue(staticMeta,
            ANDROID_REQUEST_PARTIAL_RESULT_COUNT, partialMetadataCount);
    if (partialMetadataCount <= 0) {
        LOGW("Invalid value (%d) for ANDROID_REQUEST_PARTIAL_RESULT_COUNT"
                "FIX your config", partialMetadataCount);
        partialMetadataCount = 1;
    }
    return partialMetadataCount;
}

const camera_metadata_t * PlatformData::getStaticMetadata(int cameraId)
{
    if (cameraId >= numberOfCameras()) {
        LOGE("ERROR @%s: Invalid camera: %d", __FUNCTION__, cameraId);
        cameraId = 0;
        return nullptr;
    }

    CameraProfiles * i = getInstance();

    if (!i)
        return nullptr;

    camera_metadata_t * metadata = i->mStaticMeta[cameraId];
    return metadata;
}

camera_metadata_t *PlatformData::getDefaultMetadata(int cameraId, int requestType)
{
    if (cameraId >= numberOfCameras()) {
        LOGE("ERROR @%s: Invalid camera: %d", __FUNCTION__, cameraId);
        cameraId = 0;
    }
    CameraProfiles * i = getInstance();

    if (!i)
        return nullptr;

    return i->constructDefaultMetadata(cameraId, requestType);
}

const CameraCapInfo * PlatformData::getCameraCapInfo(int cameraId)
{
    // Use MAX_CAMERAS instead of numberOfCameras() as it will cause a recursive loop
    if (cameraId > MAX_CAMERAS) {
        LOGE("ERROR @%s: Invalid camera: %d", __FUNCTION__, cameraId);
        cameraId = 0;
    }
    CameraProfiles * i = getInstance();

    if (!i)
        return nullptr;

    return i->getCameraCapInfo(cameraId);
}

/**
 * getDeviceIds
 * returns a vector of strings with a list of names to identify the device
 * the HAL is running on.
 * The list has the most specific name first and then more generic names as
 * fallback
 * The values for this strings are:
 * - If the platform supports spid the first string is a concatenation of the
 * vendor_id + platform_family_id + produc_line_id. This is always the first
 * for backwards compatibility reasons.
 *
 *  This list can be used to find the correct configuration file, either CPF or
 *  camera XML (camera3_profiles)
 *
 *  Please Note:
 *  If in non-spid platforms the identifiers in the system properties are not
 *  precise enough and a new property is used, it should be returned first.
 *
 */
status_t PlatformData::getDeviceIds(std::vector<string> &names)
{
    char prop[PATH_MAX] = {0};
    static const char *deviceIdKeys[] = {
       "ro.product.device",
       "ro.product.board",
       "ro.board.platform",
    };
    static const int DEVICE_ID_KEYS_COUNT =
        (sizeof(deviceIdKeys)/sizeof(deviceIdKeys[0]));

    for (int i = 0; i < DEVICE_ID_KEYS_COUNT ; i++) {
        if (LogHelper::__getEnviromentValue(deviceIdKeys[i], prop, sizeof(prop)) == 0)
            continue;

        names.push_back(string(prop));
    }

    return OK;
}

const char* PlatformData::boardName(void)
{
    return mCameraHWInfo->boardName();
}

const char* PlatformData::productName(void)
{
    return mCameraHWInfo->productName();
}

const char* PlatformData::manufacturerName(void)
{
    return mCameraHWInfo->manufacturerName();
}

/**
 *
 * retrieves the AIQD data file path saved on the host file system
 *
 * AIQD is triggered to store into filesystem by 3a to rembmer 3a parameters before
 * the camera exist, 3a will read the AIQD file for better 3a quality when camera starts
 *
 * \param[IN] sensorName the name of the sensor
 *
 * \return the AIQD data file path on the host file system
 */
std::string PlatformData::getAiqdFileName(const std::string& sensorName)
{
    std::string aiqdFileName = "";

    aiqdFileName.append(CAMERA_CACHE_DIR);
    aiqdFileName.append(sensorName);
    aiqdFileName.append(".aiqd");

    LOG1("@%s: aiqd file location: %s", __FUNCTION__, aiqdFileName.c_str());
    return aiqdFileName;
}

bool PlatformData::supportDualVideo(void)
{
    return mCameraHWInfo->supportDualVideo();
}

int PlatformData::getCameraDeviceAPIVersion(void)
{
    return mCameraHWInfo->getCameraDeviceAPIVersion();
}

bool PlatformData::supportExtendedMakernote(void)
{
    return mCameraHWInfo->supportExtendedMakernote();
}

bool PlatformData::supportFullColorRange(void)
{
    return mCameraHWInfo->supportFullColorRange();
}

bool PlatformData::supportIPUAcceleration(void)
{
    return mCameraHWInfo->supportIPUAcceleration();
}

status_t PlatformData::readSpId(string& spIdName, unsigned int& spIdValue)
{
    FILE *file;
    status_t ret = OK;
    string sysfsSpIdPath = "/sys/spid/";
    string fullPath;

    fullPath = sysfsSpIdPath;
    fullPath.append(spIdName);

    file = fopen(fullPath.c_str(), "rb");
    if (!file) {
        LOGE("ERROR in opening file %s", fullPath.c_str());
        return NAME_NOT_FOUND;
    }
    ret = fscanf(file, "%x", &spIdValue);
    if (ret < 0) {
        LOGE("ERROR in reading %s", fullPath.c_str());
        spIdValue = 0;
        fclose(file);
        return UNKNOWN_ERROR;
    }
    fclose(file);
    return ret;
}

void PlatformData::initAiqdInfo(int cameraIdx)
{
    CameraProfiles * i = getInstance();
    if (!i)
        return;

    auto it = i->mCameraIdToSensorName.find(cameraIdx);
    if (it == i->mCameraIdToSensorName.end())
        return;

    std::string fileName = getAiqdFileName(it->second);
    unsigned int fileSize = getAiqdFileSize(fileName);
    if (fileSize > 0) {
        if (!readAiqdDataFromFile(cameraIdx, fileName, fileSize)) {
            LOGW("Failed to open Aiqd file from system!");
        }
    }
}

unsigned int PlatformData::getAiqdFileSize(std::string fileName)
{
    LOG1("@%s", __FUNCTION__);
    struct stat fileStat;
    CLEAR(fileStat);

    if (stat(fileName.c_str(), &fileStat) != 0) {
        LOGW("can't read aiqd file or file doesn't exist, AiqdFileName = %s, error:%s",
            fileName.c_str(), strerror(errno));
        return 0;
    }

    LOG1("@%s: read aiqd file: %s, size = %jd", __FUNCTION__, fileName.c_str(), (intmax_t)fileStat.st_size);
    return fileStat.st_size;
}

bool PlatformData::readAiqdDataFromFile(int cameraIdx, const std::string fileName, int fileSize)
{
    LOG1("@%s: update aiqd data read from file %s.", __FUNCTION__, fileName.c_str());

    if (cameraIdx < 0 || cameraIdx >= MAX_CAMERAS) {
        LOGE("@%s: Invalid camera id: %d.", __FUNCTION__, cameraIdx);
        return false;
    }

    FILE *f = fopen(fileName.c_str(), "rb");
    if (!f) {
        LOGW("@%s, Failed to open Aiqd file:%s from file system!, error:%s",
            __FUNCTION__, fileName.c_str(), strerror(errno));
        return false;
    }

    std::unique_ptr<char[]> data(new char[fileSize]);
    size_t readCount = fread(data.get(), sizeof(unsigned char), fileSize, f);
    if (readCount != fileSize) {
        LOGE("read aiqd %d bytes from file: %s fail", fileSize, fileName.c_str());

        fclose(f);

        return false;
    }

    fclose(f);

    struct AiqdDataInfo& aiqdData = mCameraHWInfo->mAiqdDataInfo[cameraIdx];
    aiqdData.mData = std::move(data);
    aiqdData.mDataCapacity = fileSize;
    aiqdData.mDataSize = fileSize;
    aiqdData.mFileName = fileName;

    LOG2("@%s, aiqd fileName: %s, size: %d", __FUNCTION__, fileName.c_str(), aiqdData.mDataSize);

    return true;
}

bool PlatformData::readAiqdData(int cameraId, ia_binary_data *data)
{
    if (cameraId < 0 || cameraId >= MAX_CAMERAS) {
        LOGE("@%s: Invalid camera id: %d.", __FUNCTION__, cameraId);
        return false;
    }

    if (mCameraHWInfo->mAiqdDataInfo[cameraId].mDataSize > 0) {
        data->size = mCameraHWInfo->mAiqdDataInfo[cameraId].mDataSize;
        data->data = mCameraHWInfo->mAiqdDataInfo[cameraId].mData.get();
        LOG1("@%s: fill in Aiqd data: %p, size : %d", __FUNCTION__, data->data, data->size);
        return true;
    }

    return false;
}

void PlatformData::saveAiqdData(int cameraId, const ia_binary_data& data)
{
    if (cameraId < 0 || cameraId >= MAX_CAMERAS) {
        LOGE("@%s: Invalid cameraId: %d", __FUNCTION__, cameraId);
        return;
    }

    CameraProfiles * i = getInstance();
    if (!i)
        return;

    LOG1("@%s: save aiqd data into PlatformData, camera: %d.", __FUNCTION__, cameraId);

    struct AiqdDataInfo& aiqdData = mCameraHWInfo->mAiqdDataInfo[cameraId];

    if (aiqdData.mDataCapacity < data.size) {
        aiqdData.mData.reset(new char[data.size]);
        aiqdData.mDataCapacity = data.size;
        LOG2("@%s: camera = %d, new aiqd capacity size = %d",
            __FUNCTION__, cameraId, aiqdData.mDataCapacity);
    }
    aiqdData.mDataSize = data.size;

    MEMCPY_S(aiqdData.mData.get(), aiqdData.mDataCapacity, data.data, data.size);

    auto it = i->mCameraIdToSensorName.find(cameraId);
    if (it != i->mCameraIdToSensorName.end()) {
        aiqdData.mFileName = getAiqdFileName(it->second);
    }

    LOG2("@%s: camera = %d, aiqd capacity = %d, aiqd size = %d, data = %p, location = %s.",
            __FUNCTION__, cameraId,
            aiqdData.mDataCapacity, aiqdData.mDataSize,
            aiqdData.mData.get(), aiqdData.mFileName.c_str());
}

bool PlatformData::saveAiqdDataToFile()
{
    LOG1("@%s: save aiqd data to file.", __FUNCTION__);

    for (auto& it : mCameraHWInfo->mAiqdDataInfo) {
        if (it.mDataSize <= 0)
            continue;

        LOG1("@%s, size = %d, file location = %s, data = %p.", __FUNCTION__,
                it.mDataSize, it.mFileName.c_str(), it.mData.get());

        /* remove the existed file before do saving */
        struct stat filestat;
        if (stat(it.mFileName.c_str(), &filestat) == 0) {
            LOGW("file already exist, remove the old one, AiqdFileName = %s, error:%s",
               it.mFileName.c_str(), strerror(errno));
            if (std::remove(it.mFileName.c_str()) != 0) {
                LOGE("error when removing file: %s", it.mFileName.c_str());
                return false;
            }
        }

        FILE *f = fopen(it.mFileName.c_str(), "wb");
        if (f == nullptr) {
            LOGE("Can't save aiqd to file: %s! error:%s", it.mFileName.c_str(), strerror(errno));
            return false;
        }

        size_t writeCount = fwrite(it.mData.get(), 1, it.mDataSize, f);
        if (writeCount != it.mDataSize) {
            LOGE("Save aiqd %d bytes to file: %s fail, error:%s",
                it.mDataSize, it.mFileName.c_str(), strerror(errno));
            fclose(f);
            return false;
        }

        fflush(f);
        fclose(f);
    }

    return true;
}

/**
 * getActivePixelArray
 *
 * retrieves the Active Pixel Array (APA) static metadata entry and initializes
 * a CameraWindow structure correctly from it.
 * APA is defined as a rectangle that stores the values as
 * (xmin,ymin, width,height)
 *
 * \param cameraId [IN]: Camera id of the device to query the APA
 * \returns CameraWindow initialized with the APA or empty if it was not found
 *                       but this should not happen
 */
CameraWindow PlatformData::getActivePixelArray(int cameraId)
{
    CameraWindow apa;
    camera_metadata_ro_entry entry;
    const camera_metadata *staticMeta = getStaticMetadata(cameraId);
    if (CC_UNLIKELY(staticMeta == nullptr)) {
        LOGE("@%s: Invalid camera id (%d) could not get static metadata",
                __FUNCTION__, cameraId);
        return apa;
    }

    find_camera_metadata_ro_entry(staticMeta,
                                  ANDROID_SENSOR_INFO_ACTIVE_ARRAY_SIZE,
                                  &entry);
    if (entry.count >= 4) {
        ia_coordinate topLeft;
        INIT_COORDINATE(topLeft,entry.data.i32[0],entry.data.i32[1]);
        apa.init(topLeft,
                 entry.data.i32[2], //width
                 entry.data.i32[3], //height
                 0);
    } else {
        LOGE("could not find ACTIVE_ARRAY_SIZE- INVALID XML configuration!!");
    }
    return apa;
}

float PlatformData::getStepEv(int cameraId)
{
    // Get the ev step
    android::CameraMetadata staticMeta;
    float stepEV = 1 / 3.0f;
    int count = 0;
    staticMeta = getStaticMetadata(cameraId);
    camera_metadata_rational_t* aeCompStep =
        (camera_metadata_rational_t*)MetadataHelper::getMetadataValues(staticMeta,
                                     ANDROID_CONTROL_AE_COMPENSATION_STEP,
                                     TYPE_RATIONAL,
                                     &count);
    if (count == 1 && aeCompStep != nullptr) {
        stepEV = (float)aeCompStep->numerator / aeCompStep->denominator;
    }
    return stepEV;

}

/**
 * static convenience getter for cpf and cmc data.
 */
status_t PlatformData::getCpfAndCmc(ia_binary_data& cpfData,
                                    ia_cmc_t** cmcData,
                                    uintptr_t* cmcHandle,
                                    int cameraId,
                                    string mode)
{
    const AiqConf* aiqConf = getAiqConfiguration(cameraId, mode);
    if (CC_UNLIKELY(aiqConf == nullptr)) {
        LOGE("CPF file was not initialized ");
        return NO_INIT;
    }
    cpfData.data = aiqConf->ptr();
    cpfData.size = aiqConf->size();

    const Intel3aCmc* cmc = aiqConf->getCMC();
    CheckError(cmc == nullptr, NO_INIT, "@%s, call getCMC() fails", __FUNCTION__);

    if (cmcData) {
        *cmcData = cmc->getCmc();
        CheckError(*cmcData == nullptr, NO_INIT, "@%s, call getCmc() fails", __FUNCTION__);
    }

    if (cmcHandle) {
        *cmcHandle = cmc->getCmcHandle();
        CheckError(reinterpret_cast<ia_cmc_t*>(*cmcHandle) == nullptr,
            NO_INIT, "@%s, call getCmcHandle() fails", __FUNCTION__);
    }

    return OK;
}

bool PlatformData::isFaceAeEnabled(int cameraId)
{
    CheckError(mInstance == nullptr, false, "@%s, mInstance is nullptr", __FUNCTION__);
    return mInstance->isFaceAeEnabled(cameraId);
}

int PlatformData::faceEngineRunningInterval(int cameraId)
{
    CheckError(mInstance == nullptr, false, "@%s, mInstance is nullptr", __FUNCTION__);
    return mInstance->faceEngineRunningInterval(cameraId);
}

int PlatformData::readNvmDataFromDevice(int cameraId)
{
    CheckError(mInstance == nullptr, false, "@%s, mInstance is nullptr", __FUNCTION__);

    return mInstance->readNvmDataFromDevice(cameraId);
}

CameraHWInfo::CameraHWInfo() :
        mMainDevicePathName(DEFAULT_MAIN_DEVICE),
        mHasMediaController(false)
{
    mBoardName = "<not set>";
    mProductName = "<not_set>";
    mManufacturerName = "<not set>";
    mCameraDeviceAPIVersion = CAMERA_DEVICE_API_VERSION_3_3;
    mSupportDualVideo = false;
    mSupportExtendedMakernote = false;
    mSupportFullColorRange = true;
    mSupportIPUAcceleration = false;

    // -1 means mPreviewHALFormat is not set
    mPreviewHALFormat = -1;

    CLEAR(mDeviceInfo);
}

status_t CameraHWInfo::init(const std::string &mediaDevicePath)
{
    mMediaControllerPathName = mediaDevicePath;
    readProperty();

    return initDriverList();
}

status_t CameraHWInfo::initDriverList()
{
    LOG1("@%s", __FUNCTION__);
    status_t ret = OK;
    if (mSensorInfo.size() > 0) {
        // We only need to go through the drivers once
        return OK;
    }

    // check whether we are in a platform that supports media controller (mc)
    // or in one where a main device (md) can enumerate the sensors
    struct stat sb;
    int mcExist = stat(mMediaControllerPathName.c_str(), &sb);

    if (mcExist == 0) {
        mHasMediaController = true;
        ret = findMediaControllerSensors();
        ret |= findMediaDeviceInfo();
    } else {
        LOGE("Could not find sensor names");
        ret = NO_INIT;
    }

    for (unsigned i = 0 ;i < mSensorInfo.size(); ++i)
        LOG1("@%s, mSensorName:%s, mDeviceName:%s, port:%d", __FUNCTION__,
            mSensorInfo[i].mSensorName.c_str(), mSensorInfo[i].mDeviceName.c_str(), mSensorInfo[i].mIspPort);

    return ret;
}

status_t CameraHWInfo::readProperty()
{
    std::string cameraPropertyPath = std::string(CAMERA_CACHE_DIR) + std::string(CAMERA_PROPERTY_FILE);
    std::fstream props(cameraPropertyPath.c_str(), std::ios::in);

    if (!props.is_open()) {
        LOGW("Failed to load camera property file.");
        return UNKNOWN_ERROR;
    }

    const std::string kManufacturer = "ro.product.manufacturer";
    const std::string kModel = "ro.product.model";
    const std::string kDelimiter = "=";
    std::map<std::string, std::string> properties;

    while (!props.eof()) {
        size_t pos;
        std::string line, key, value;

        std::getline(props, line);
        pos = line.find(kDelimiter);
        if (pos != std::string::npos) {
            key = line.substr(0, pos);
            value = line.substr(pos + 1);
            properties[key] = value;
            LOG2("%s, new key,value: %s,%s", __FUNCTION__, key.c_str(), value.c_str());
        }
    }

    if (properties.find(kManufacturer) != properties.end()) {
        mManufacturerName = properties[kManufacturer];
    }
    if (properties.find(kModel) != properties.end()) {
        mProductName = properties[kModel];
    }

    return OK;
}

status_t CameraHWInfo::findMediaControllerSensors()
{
    status_t ret = OK;
    int fd = open(mMediaControllerPathName.c_str(), O_RDONLY);
    if (fd == -1) {
        LOGW("Could not openg media controller device: %s!", strerror(errno));
        return ENXIO;
    }

    struct media_entity_desc entity;
    CLEAR(entity);
    do {
        // Go through the list of media controller entities
        entity.id |= MEDIA_ENT_ID_FLAG_NEXT;
        if (ioctl(fd, MEDIA_IOC_ENUM_ENTITIES, &entity) < 0) {
            if (errno == EINVAL) {
                // Ending up here when no more entities left.
                // Will simply 'break' if everything was ok
                if (mSensorInfo.size() == 0) {
                    // No registered drivers found
                    LOGE("ERROR no sensor driver registered in media controller!");
                    ret = NO_INIT;
                }
            } else {
                LOGE("ERROR in browsing media controller entities: %s!", strerror(errno));
                ret = FAILED_TRANSACTION;
            }
            break;
        } else {
            if (entity.type == MEDIA_ENT_T_V4L2_SUBDEV_SENSOR) {
                // A driver has been found!
                // The driver is using sensor name when registering
                // to media controller (we will truncate that to
                // first space, if any)
                SensorDriverDescriptor drvInfo;
                drvInfo.mSensorName = entity.name;
                drvInfo.mSensorDevType = SENSOR_DEVICE_MC;

                unsigned major = entity.v4l.major;
                unsigned minor = entity.v4l.minor;

                // Go through the subdevs one by one, see which one
                // corresponds to this driver (if there is an error,
                // the looping ends at 'while')
                ret = initDriverListHelper(major, minor, drvInfo);
            }
        }
    } while (!ret);

    if (close(fd)) {
        LOGE("ERROR in closing media controller: %s!", strerror(errno));
        if (!ret) ret = EPERM;
    }

    return ret;
}

status_t CameraHWInfo::findMediaDeviceInfo()
{
    status_t ret = OK;
    int fd = open(mMediaControllerPathName.c_str(), O_RDONLY);
    if (fd == -1) {
        LOGW("Could not openg media controller device: %s!", strerror(errno));
        return UNKNOWN_ERROR;
    }

    CLEAR(mDeviceInfo);
    if (ioctl(fd, MEDIA_IOC_DEVICE_INFO, &mDeviceInfo) < 0) {
        LOGE("ERROR in browsing media device information: %s!", strerror(errno));
        ret = FAILED_TRANSACTION;
    } else {
        LOG1("Media device: %s", mDeviceInfo.driver);
    }

    if (close(fd)) {
        LOGE("ERROR in closing media controller: %s!", strerror(errno));

        if (!ret) {
            ret = PERMISSION_DENIED;
        }
    }

    return ret;
}

/**
 * Function to get the CSI port number a sensor is connected to.
 * Use mediacontroller to go through the links to find the CSI entity
 * and trim the port number from it.
 *
 * \param[IN] deviceName sensor full name
 * \param[OUT] portId CSI port number
 *
 */
status_t CameraHWInfo::getCSIPortID(const std::string &deviceName, int &portId)
{
    LOG1("@%s", __FUNCTION__);
    status_t status = NO_ERROR;
    std::shared_ptr<MediaEntity> mediaEntity = nullptr;
    std::vector<string> names;
    string name;
    std::vector<string> nameTemplateVec;

    // Kernel driver should follow one of these 3 templates to report the CSI port, else this
    // parsing will fail. The format is <...CSI...> port-number
    const char *CSI_RX_PORT_NAME_TEMPLATE1 = "CSI-2";
    const char *CSI_RX_PORT_NAME_TEMPLATE2 = "CSI2-port";
    const char *CSI_RX_PORT_NAME_TEMPLATE3 = "TPG";
    nameTemplateVec.push_back(CSI_RX_PORT_NAME_TEMPLATE1);
    nameTemplateVec.push_back(CSI_RX_PORT_NAME_TEMPLATE2);
    nameTemplateVec.push_back(CSI_RX_PORT_NAME_TEMPLATE3);

    std::shared_ptr<MediaController> mediaCtl = std::make_shared<MediaController>(mMediaControllerPathName.c_str());

    status = mediaCtl->init();
    if (status != NO_ERROR) {
        LOGE("Error initializing Media Controller");
        return status;
    }

    status = mediaCtl->getMediaEntity(mediaEntity, deviceName.c_str());
    if (status != NO_ERROR) {
        LOGE("Failed to get media entity by sensor name %s", deviceName.c_str());
        return status;
    }

    if (mediaEntity->getType() != SUBDEV_SENSOR) {
        LOGE("Media entity not sensor type");
        return UNKNOWN_ERROR;
    }

    // Traverse the sinks till we get CSI port
    while (1) {
        names.clear();
        status = mediaCtl->getSinkNamesForEntity(mediaEntity, names);
        if (status != NO_ERROR) {
            LOGE("Error getting sink names for entity %s", mediaEntity->getName());
            return UNKNOWN_ERROR;
        }

        // For sensor type there will be only one sink
        if (names.size() != 1) {
            LOGW("Number of sinks for sensor not 1 it is %zu", names.size());
        }
        if (names.size() == 0) {
            LOGW("No sink names available for %s", deviceName.c_str());
            return 0;
        }

        name = names[0];
        size_t pos = 0;
        for (auto &nameTemplate : nameTemplateVec) {
            // check if name is CSI port
            if ((pos = name.find(nameTemplate)) != string::npos) {
                LOG2("found CSI port name = %s", name.c_str());
                // Trim the port id from CSI port name
                name = name.substr(pos + nameTemplate.length());
                portId = atoi(name.c_str());
                if (portId < 0) {
                    LOGE("Error getting port id %d", portId);
                    return UNKNOWN_ERROR;
                }
                return status;
            }
        }
        // Get media entity for new name
        mediaEntity = nullptr;
        status = mediaCtl->getMediaEntity(mediaEntity, name.c_str());
        if (status != NO_ERROR) {
            LOGE("Failed to get media entity by name %s", name.c_str());
            break;
        }
    }

    return status;
}

/**
 * Get all available sensor modes from the driver
 *
 * Function gets all currently available sensor modes from the driver
 * and returns them in a vector.
 *
 * \param[in] sensorName    Name of the sensor
 * \param[out] sensorModes  Vector of available sensor modes for this sensor
 */
status_t CameraHWInfo::getAvailableSensorModes(const std::string &sensorName,
                                               SensorModeVector &sensorModes) const
{
    status_t ret = NO_ERROR;
    const char *devname;
    std::string sDevName;

    for (size_t i = 0; i < mSensorInfo.size(); i++) {
        if (mSensorInfo[i].mSensorName != sensorName)
            continue;

        std::ostringstream stringStream;
        stringStream << "/dev/" << mSensorInfo[i].mDeviceName.c_str();
        sDevName = stringStream.str();
    }
    devname = sDevName.c_str();
    std::shared_ptr<cros::V4L2Subdevice> device = std::make_shared<cros::V4L2Subdevice>(devname);

    ret = device->Open(O_RDWR);
    if (ret != NO_ERROR) {
        LOGE("Error opening device (%s)", devname);
        return ret;
    }

    // Get query control for sensor mode to determine max value
    v4l2_queryctrl sensorModeControl;
    CLEAR(sensorModeControl);
    sensorModeControl.id = CRL_CID_SENSOR_MODE;
    ret = device->QueryControl(&sensorModeControl);
    if (ret != NO_ERROR) {
        LOGE("Couldn't get sensor mode range");
        device->Close();
        return UNKNOWN_ERROR;
    }
    uint32_t max = sensorModeControl.maximum;
    v4l2_querymenu menu;
    CLEAR(menu);
    menu.id = CRL_CID_SENSOR_MODE;

    // Loop through menu and add indexes and names to vector
    for (menu.index = 0; menu.index <= max; menu.index++) {
        ret = (device->QueryMenu(&menu));
        if (ret != NO_ERROR) {
            LOGE("Error opening query menu at index: %d", menu.index);
        } else {
            sensorModes.push_back(std::make_pair(uint32_t(menu.index),
                                  reinterpret_cast<char *>(menu.name)));
        }
    }
    ret = device->Close();
    if (ret != NO_ERROR)
        LOGE("Error closing device (%s)", devname);

    return NO_ERROR;
}

void CameraHWInfo::getMediaCtlElementNames(std::vector<std::string> &elementNames) const
{
    int fd = open(mMediaControllerPathName.c_str(), O_RDONLY);
    CheckError(fd == -1, VOID_VALUE, "@%s, Could not open media controller device: %s",
           __FUNCTION__, strerror(errno));

    struct media_entity_desc entity;
    CLEAR(entity);
    entity.id |= MEDIA_ENT_ID_FLAG_NEXT;

    while (ioctl(fd, MEDIA_IOC_ENUM_ENTITIES, &entity) >= 0) {
        elementNames.push_back(std::string(entity.name));
        LOG2("@%s, entity name:%s, id:%d", __FUNCTION__, entity.name, entity.id);
        entity.id |= MEDIA_ENT_ID_FLAG_NEXT;
    }

    CheckError(close(fd) > 0, VOID_VALUE, "@%s, Error in closing media controller: %s",
           __FUNCTION__, strerror(errno));
}

std::string CameraHWInfo::getFullMediaCtlElementName(const std::vector<std::string> elementNames,
                                                     const char *value) const
{
    for (auto &it: elementNames) {
        if (it.find(value) != std::string::npos) {
            LOG2("@%s, find match element name: %s, new name: %s",
                __FUNCTION__, value, it.c_str());
            return it;
        }
    }

    LOGE("@%s, No match element name is found for %s!", __FUNCTION__, value);
    return value;
}

status_t CameraHWInfo::initDriverListHelper(unsigned major, unsigned minor, SensorDriverDescriptor& drvInfo)
{
    LOG1("@%s", __FUNCTION__);
    int portId = 0;
    status_t status = UNKNOWN_ERROR;
    std::size_t pos = string::npos;

    string subdevPathName = "/dev/v4l-subdev";
    string subdevPathNameN;

    for (int n = 0; n < MAX_SUBDEV_ENUMERATE; n++) {
        subdevPathNameN = subdevPathName + std::to_string(n);
        struct stat fileInfo;
        CLEAR(fileInfo);
        if (stat(subdevPathNameN.c_str(), &fileInfo) < 0) {
            if (errno == ENOENT) {
                // We end up here when there is no Nth subdevice
                // but there might be more subdevices, so continue.
                // For an example if there are v4l subdevices 0, 4, 5 and 6
                // we come here for subdevices 1, 2 and 3.
                LOGI("Subdev missing: \"%s\"!", subdevPathNameN.c_str());
                continue;
            } else {
                LOGE("ERROR querying sensor subdev filestat for \"%s\": %s!",
                     subdevPathNameN.c_str(), strerror(errno));
                return FAILED_TRANSACTION;
            }
        }
        if ((major == MAJOR(fileInfo.st_rdev)) && (minor == MINOR(fileInfo.st_rdev))) {
            drvInfo.mDeviceName = subdevPathNameN;
            pos = subdevPathNameN.rfind('/');
            if (pos != std::string::npos)
                drvInfo.mDeviceName = subdevPathNameN.substr(pos + 1);

            drvInfo.mIspPort = (ISP_PORT)n; // Unused for media-ctl sensors
            status = getCSIPortID(drvInfo.mSensorName, portId);
            if (status != NO_ERROR) {
                LOGE("error getting CSI port id %d", portId);
                return status;
            }

            /*
             * Parse i2c address from sensor name.
             * It is the last word in the sensor name string, so find last
             * space and take the rest of the string.
             */
            pos = drvInfo.mSensorName.rfind(" ");
            drvInfo.mI2CAddress = drvInfo.mSensorName.substr(pos + 1);

            /*
             *  Now that we are done using the sensor name cut the name to
             *  first space, to get the actual name. First we check if
             *  it is tpg.
             */
            size_t i = drvInfo.mSensorName.find("TPG");
            if (CC_LIKELY(i != std::string::npos)) {
                drvInfo.mSensorName = drvInfo.mSensorName.substr(i,3);
                drvInfo.csiPort = portId;
                /* Because of several ports for TPG in media entity,
                 * just use port 0 as source input.
                 */
                if (drvInfo.csiPort == 0)
                    mSensorInfo.push_back(drvInfo);

            } else {
                i = drvInfo.mSensorName.find(" ");
                if (CC_LIKELY(i != std::string::npos)) {
                    drvInfo.mSensorName = drvInfo.mSensorName.substr(0, i);
                } else {
                    LOGW("Could not extract sensor name correctly");
                }

                drvInfo.csiPort = portId;
                mSensorInfo.push_back(drvInfo);
            }
            LOG1("Registered sensor driver \"%s\" found for sensor \"%s\", CSI port:%d",
                 drvInfo.mDeviceName.c_str(), drvInfo.mSensorName.c_str(),
                 drvInfo.csiPort);
            // All ok
            break;
        }
    }

    return OK;
}

} /* namespace intel */
} /* namespace cros */
